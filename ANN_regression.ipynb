{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3637a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3713727c",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87730c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henry\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d6f5b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dependent_var_cont</th>\n",
       "      <th>dependent_var_binary</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.662495</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.020203</td>\n",
       "      <td>-1.272966</td>\n",
       "      <td>1.794028</td>\n",
       "      <td>4.186261</td>\n",
       "      <td>-1.583283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.992336</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.094311</td>\n",
       "      <td>-0.891598</td>\n",
       "      <td>1.539495</td>\n",
       "      <td>3.980735</td>\n",
       "      <td>-1.964685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.522223</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.235722</td>\n",
       "      <td>-1.347074</td>\n",
       "      <td>1.302948</td>\n",
       "      <td>3.626135</td>\n",
       "      <td>-1.755620</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.127296</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.210721</td>\n",
       "      <td>-0.274437</td>\n",
       "      <td>1.376186</td>\n",
       "      <td>3.812485</td>\n",
       "      <td>-2.587604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.239854</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.198451</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>0.215049</td>\n",
       "      <td>3.229904</td>\n",
       "      <td>-2.029509</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dependent_var_cont  dependent_var_binary  feature_0  feature_1  feature_2  \\\n",
       "0            4.662495                     1  -0.020203  -1.272966   1.794028   \n",
       "1            4.992336                     1  -0.094311  -0.891598   1.539495   \n",
       "2            4.522223                     1  -0.235722  -1.347074   1.302948   \n",
       "3            4.127296                     0  -0.210721  -0.274437   1.376186   \n",
       "4            3.239854                     0  -0.198451  -1.203973   0.215049   \n",
       "\n",
       "   feature_3  feature_4  feature_5  feature_6  feature_7  feature_8  \n",
       "0   4.186261  -1.583283          1          0          0          0  \n",
       "1   3.980735  -1.964685          0          0          1          0  \n",
       "2   3.626135  -1.755620          0          1          0          0  \n",
       "3   3.812485  -2.587604          0          1          0          0  \n",
       "4   3.229904  -2.029509          0          1          0          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_0.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90833011",
   "metadata": {},
   "source": [
    "split into training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c685644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad8a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5','feature_6', 'feature_7','feature_8']].values\n",
    "y = df['dependent_var_cont'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb50d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a218f",
   "metadata": {},
   "source": [
    "scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92264d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40f62081",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)  #combines scaler.fit(X_train)  then X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1b154",
   "metadata": {},
   "source": [
    "create artificial neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c0d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68382651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b950a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 16.8396 - val_loss: 16.7698\n",
      "Epoch 2/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.7135 - val_loss: 16.2593\n",
      "Epoch 3/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.0602 - val_loss: 15.6990\n",
      "Epoch 4/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.5854 - val_loss: 15.0378\n",
      "Epoch 5/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.8122 - val_loss: 14.2350\n",
      "Epoch 6/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.6215 - val_loss: 13.3091\n",
      "Epoch 7/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.6789 - val_loss: 12.3121\n",
      "Epoch 8/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.8772 - val_loss: 11.1836\n",
      "Epoch 9/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.1720 - val_loss: 9.8401\n",
      "Epoch 10/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5295 - val_loss: 8.3903\n",
      "Epoch 11/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3152 - val_loss: 6.9412\n",
      "Epoch 12/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7506 - val_loss: 5.5478\n",
      "Epoch 13/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2784 - val_loss: 4.2056\n",
      "Epoch 14/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9717 - val_loss: 2.9459\n",
      "Epoch 15/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8447 - val_loss: 1.9173\n",
      "Epoch 16/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7298 - val_loss: 1.1175\n",
      "Epoch 17/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1434 - val_loss: 0.6093\n",
      "Epoch 18/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6298 - val_loss: 0.3877\n",
      "Epoch 19/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4985 - val_loss: 0.3307\n",
      "Epoch 20/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4022 - val_loss: 0.3222\n",
      "Epoch 21/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3776 - val_loss: 0.3165\n",
      "Epoch 22/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3731 - val_loss: 0.3226\n",
      "Epoch 23/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3965 - val_loss: 0.2953\n",
      "Epoch 24/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3650 - val_loss: 0.2857\n",
      "Epoch 25/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3539 - val_loss: 0.2795\n",
      "Epoch 26/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3055 - val_loss: 0.2717\n",
      "Epoch 27/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3117 - val_loss: 0.2655\n",
      "Epoch 28/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3209 - val_loss: 0.2587\n",
      "Epoch 29/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3318 - val_loss: 0.2559\n",
      "Epoch 30/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3029 - val_loss: 0.2515\n",
      "Epoch 31/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2765 - val_loss: 0.2439\n",
      "Epoch 32/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2819 - val_loss: 0.2428\n",
      "Epoch 33/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2853 - val_loss: 0.2358\n",
      "Epoch 34/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2838 - val_loss: 0.2410\n",
      "Epoch 35/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2755 - val_loss: 0.2313\n",
      "Epoch 36/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2599 - val_loss: 0.2316\n",
      "Epoch 37/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2883 - val_loss: 0.2257\n",
      "Epoch 38/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2463 - val_loss: 0.2242\n",
      "Epoch 39/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2698 - val_loss: 0.2222\n",
      "Epoch 40/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2817 - val_loss: 0.2416\n",
      "Epoch 41/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2692 - val_loss: 0.2200\n",
      "Epoch 42/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2342 - val_loss: 0.2203\n",
      "Epoch 43/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2365 - val_loss: 0.2180\n",
      "Epoch 44/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2685 - val_loss: 0.2217\n",
      "Epoch 45/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2394 - val_loss: 0.2205\n",
      "Epoch 46/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2357 - val_loss: 0.2208\n",
      "Epoch 47/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2308 - val_loss: 0.2152\n",
      "Epoch 48/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2386 - val_loss: 0.2139\n",
      "Epoch 49/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2289 - val_loss: 0.2147\n",
      "Epoch 50/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2313 - val_loss: 0.2137\n",
      "Epoch 51/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2610 - val_loss: 0.2136\n",
      "Epoch 52/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2416 - val_loss: 0.2141\n",
      "Epoch 53/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2309 - val_loss: 0.2202\n",
      "Epoch 54/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2543 - val_loss: 0.2135\n",
      "Epoch 55/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2129 - val_loss: 0.2186\n",
      "Epoch 56/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2138 - val_loss: 0.2171\n",
      "Epoch 57/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2322 - val_loss: 0.2138\n",
      "Epoch 58/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2395 - val_loss: 0.2130\n",
      "Epoch 59/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2105 - val_loss: 0.2153\n",
      "Epoch 60/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2243 - val_loss: 0.2132\n",
      "Epoch 61/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2368 - val_loss: 0.2141\n",
      "Epoch 62/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2264 - val_loss: 0.2208\n",
      "Epoch 63/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2289 - val_loss: 0.2137\n",
      "Epoch 64/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2330 - val_loss: 0.2231\n",
      "Epoch 65/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2458 - val_loss: 0.2170\n",
      "Epoch 66/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2268 - val_loss: 0.2248\n",
      "Epoch 67/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2414 - val_loss: 0.2134\n",
      "Epoch 68/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2179 - val_loss: 0.2137\n",
      "Epoch 69/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2298 - val_loss: 0.2187\n",
      "Epoch 70/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2357 - val_loss: 0.2152\n",
      "Epoch 71/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2039 - val_loss: 0.2266\n",
      "Epoch 72/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2269 - val_loss: 0.2129\n",
      "Epoch 73/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2178 - val_loss: 0.2244\n",
      "Epoch 74/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2309 - val_loss: 0.2138\n",
      "Epoch 75/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2227 - val_loss: 0.2136\n",
      "Epoch 76/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2311 - val_loss: 0.2151\n",
      "Epoch 77/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2173 - val_loss: 0.2181\n",
      "Epoch 78/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2327 - val_loss: 0.2162\n",
      "Epoch 79/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2422 - val_loss: 0.2137\n",
      "Epoch 80/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2400 - val_loss: 0.2183\n",
      "Epoch 81/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2203 - val_loss: 0.2233\n",
      "Epoch 82/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2477 - val_loss: 0.2172\n",
      "Epoch 83/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2330 - val_loss: 0.2130\n",
      "Epoch 84/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2400 - val_loss: 0.2145\n",
      "Epoch 85/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2201 - val_loss: 0.2149\n",
      "Epoch 86/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2193 - val_loss: 0.2190\n",
      "Epoch 87/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2277 - val_loss: 0.2149\n",
      "Epoch 88/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2305 - val_loss: 0.2169\n",
      "Epoch 89/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2606 - val_loss: 0.2142\n",
      "Epoch 90/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2405 - val_loss: 0.2145\n",
      "Epoch 91/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2329 - val_loss: 0.2139\n",
      "Epoch 92/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2090 - val_loss: 0.2132\n",
      "Epoch 93/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2262 - val_loss: 0.2150\n",
      "Epoch 94/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2321 - val_loss: 0.2181\n",
      "Epoch 95/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2410 - val_loss: 0.2138\n",
      "Epoch 96/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2253 - val_loss: 0.2131\n",
      "Epoch 97/600\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2109 - val_loss: 0.2135\n",
      "Epoch 97: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b571c58bb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode=\"min\", verbose=1, patience=25)  #early stop makes model quit training when over fitting starts happening\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(9, activation=\"relu\"))    #rule of thumb: X_train has 9 features so start with 9\n",
    "model.add(Dense(4, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(1, activation=None))\n",
    "\n",
    "#Choosing and optimizer and loss:\n",
    "# for a regression problem: model.compile(optimizer='rmsprop', loss='mse')\n",
    "# also optimizer=\"adam\" works as well\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x=X_train, y=y_train,\n",
    "          validation_data=(X_test, y_test),       #validation_data argument gives you option to compare training and test validation\n",
    "          epochs=600, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "#if data is vary large consider providing a number for the batch_size argument,\n",
    "#i.e batch_side =128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05ccd292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2833a24",
   "metadata": {},
   "source": [
    "## How to interpret chart above:\n",
    "If orange line starts to rise, then there is indication of overfitting.\n",
    "Above that is not the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d93365",
   "metadata": {},
   "source": [
    "## Model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9741e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f2710d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2134949117898941"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.46205509605445766"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.36369706823751824"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "#mean_squared_error(y_test, predictions)\n",
    "\n",
    "#get mean square error on test set\n",
    "display(model.evaluate(X_test, y_test, verbose=0))\n",
    "\n",
    "#get root mean squared error\n",
    "display(np.sqrt(model.evaluate(X_test, y_test, verbose=0)))\n",
    "\n",
    "#mean_absolute_error most straight forward evaluation metric\n",
    "display(mean_absolute_error(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a30e4",
   "metadata": {},
   "source": [
    "## Is a mean_absolute_error good?\n",
    "depends on the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0414c7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    630.000000\n",
       "mean       4.090921\n",
       "std        0.742231\n",
       "min        2.543176\n",
       "25%        3.520978\n",
       "50%        4.072353\n",
       "75%        4.625925\n",
       "max        5.822928\n",
       "Name: dependent_var_cont, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dependent_var_cont'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f40b73b",
   "metadata": {},
   "source": [
    "The mean of the dependent variable is 4.09, which means a mean_absolute_error of 0.39 means the model is on average off by 0.36/4.09 or approximately 10 percent. It is up to the user if that is a good score or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a16141",
   "metadata": {},
   "source": [
    "## Predicting with new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e0597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#           feature_0, feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7, feature_8\n",
    "new_data = [[-0.083382, -1.203973, 0.829530, 3.958072,  -2.071871, 1, 0, 1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d430258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.501321]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = scaler.transform(new_data)\n",
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd934c5",
   "metadata": {},
   "source": [
    "## saving a model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ac88d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fc98936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('my_regression_model.h5')\n",
    "model.save('my_regression_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8d80e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "##useing the saved model in the next notebook:\n",
    "#from tensorflow.keras.models import load_model\n",
    "#later_model = load_model('my_regression_model.keras')\n",
    "#later_model.predict(scaler.transform([[0.964006, 3.726185, 0.180000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1540c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da4183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
